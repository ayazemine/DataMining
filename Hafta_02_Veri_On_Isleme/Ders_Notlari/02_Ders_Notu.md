# Hafta 2: Veri Ã–n Ä°ÅŸleme ve Veri Kalitesi

## ğŸ“‹ Hafta Hedefleri
- Veri kalitesi problemlerini tanÄ±mlama
- Veri temizleme tekniklerini Ã¶ÄŸrenme
- Eksik veri yÃ¶netim stratejilerini uygulama
- Veri dÃ¶nÃ¼ÅŸtÃ¼rme ve normalizasyon yapabilme
- Pandas kÃ¼tÃ¼phanesi ile pratik veri iÅŸleme

## ğŸ“š Teorik Ä°Ã§erik

### 1. Veri Kalitesi (Data Quality)

Veri madenciliÄŸinin baÅŸarÄ±sÄ±, kullanÄ±lan verinin kalitesine doÄŸrudan baÄŸlÄ±dÄ±r ("Garbage In, Garbage Out"). Kaliteli veri, amaca uygunluÄŸu ifade eder.

#### Veri Kalitesi BoyutlarÄ± (6 Temel Boyut)
Veri kalitesi genellikle 6 ana boyutta deÄŸerlendirilir:

![datadimension](https://images.ctfassets.net/7p3vnbbznfiw/7nxnoLC5va86n2dYIqoCdJ/c468ee8c8d25d0b702abdac2ba53a486/6.-6-elements-of-data-quality--1024x768.png)

1.  **TamlÄ±k (Completeness):** 
    - Bir veri setindeki eksik verilerin yÃ¼zdesi, tamlÄ±ÄŸÄ± belirlemek iÃ§in kullanÄ±lÄ±r.
    - *Not:* Mal ve hizmetlere iliÅŸkin verilerin doÄŸruluÄŸu, potansiyel alÄ±cÄ±larÄ±n satÄ±ÅŸ kalemlerini deÄŸerlendirmesi, karÅŸÄ±laÅŸtÄ±rmasÄ± ve seÃ§mesi iÃ§in de esastÄ±r.

2.  **GÃ¼ncellik (Timeliness):** 
    - Verinin herhangi bir zamanda ne kadar gÃ¼ncel veya eski olduÄŸunu ifade eder.
    - *Ã–rnek:* MÃ¼ÅŸteri verileriniz 2008 yÄ±lÄ±na aitse ve ÅŸu an 2021 yÄ±lÄ±ndaysanÄ±z, gÃ¼ncellik ile ilgili ciddi bir sorun vardÄ±r.

3.  **GeÃ§erlilik (Validity):** 
    - Belirli firma politikalarÄ±na, prosedÃ¼rlerine veya formatlarÄ±na uymayan veriler geÃ§ersiz kabul edilir.
    - *Ã–rnek:* Bir mÃ¼ÅŸterinin doÄŸum tarihi birÃ§ok sistem tarafÄ±ndan istenebilir. Ancak tÃ¼ketici doÄŸum tarihini yanlÄ±ÅŸ formatta veya imkansÄ±z bir tarih olarak girerse, veri kalitesi doÄŸrudan etkilenir.

4.  **BÃ¼tÃ¼nlÃ¼k (Integrity):** 
    - Bilginin ne kadar gÃ¼venilir (dependable) ve itimat edilir (trustworthy) olduÄŸu veri bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ olarak adlandÄ±rÄ±lÄ±r.
    - *Soru:* Elimizdeki gerÃ§ekler ve istatistikler ne kadar doÄŸru ve gÃ¼venilirdir?

5.  **Benzersizlik (Uniqueness):** 
    - MÃ¼ÅŸteri profilleriyle en sÄ±k iliÅŸkilendirilen veri kalitesi niteliÄŸidir.
    - Uzun vadeli karlÄ±lÄ±k ve baÅŸarÄ±, genellikle her tÃ¼keticiye baÄŸlÄ± performans Ã¶lÃ§Ã¼mleri dahil olmak Ã¼zere, benzersiz mÃ¼ÅŸteri verilerinin hatasÄ±z derlenmesine dayanÄ±r (MÃ¼kerrer kayÄ±tlarÄ±n olmamasÄ±).

6.  **TutarlÄ±lÄ±k (Consistency):** 
    - Analitik Ã§alÄ±ÅŸmalar en sÄ±k veri tutarlÄ±lÄ±ÄŸÄ± ile iliÅŸkilendirilir.
    - Bilgi toplama kaynaÄŸÄ±nÄ±n, departmanÄ±n veya ÅŸirketin belirli hedeflerine uygun olarak verileri doÄŸru bir ÅŸekilde edindiÄŸini ve farklÄ± kaynaklar arasÄ±nda Ã§eliÅŸki olmadÄ±ÄŸÄ±nÄ± garanti eder.

#### Temel Veri SorunlarÄ±
1.  **GÃ¼rÃ¼ltÃ¼ (Noise):** Veri iÃ§indeki rastgele hatalar veya varyans. (Ã–rn: SensÃ¶r Ä±sÄ±nmasÄ± nedeniyle GPS sinyalindeki 2 metrelik sapma).
2.  **AykÄ±rÄ± DeÄŸerler (Outliers):** Verinin genel daÄŸÄ±lÄ±mÄ±ndan istatistiksel olarak Ã§ok sapan deÄŸerler. (Ã–rn: Ortalama maaÅŸÄ±n 20.000 TL olduÄŸu bir grupta bir kiÅŸinin 1.000.000 TL almasÄ±).
3.  **Eksik DeÄŸerler (Missing Values):** KaydedilmemiÅŸ veriler. En sÄ±k karÅŸÄ±laÅŸÄ±lan problemdir.

### 2. Eksik DeÄŸerler (Missing Values)

Eksik veriyi yÃ¶netmek iÃ§in Ã¶ncelikle **nedenini** anlamak gerekir. KÃ¶rlemesine doldurma yapmak (imputation) yanlÄ±lÄ±ÄŸa (bias) yol aÃ§abilir.

#### Eksiklik MekanizmalarÄ±
1.  **MCAR (Missing Completely At Random - Tamamen Rastgele):**
    - Eksiklik verinin kendisinden veya diÄŸer deÄŸiÅŸkenlerden baÄŸÄ±msÄ±zdÄ±r.
    - *Ã–rnek:* Laboratuvarda numune taÅŸÄ±yan tÃ¼pÃ¼n yanlÄ±ÅŸlÄ±kla kÄ±rÄ±lmasÄ±.
    - *Analiz:* Veri kaybÄ± sadece Ã¶rneklem boyutunu azaltÄ±r, sonucu Ã§arpÄ±tmaz (unbiased).

2.  **MAR (Missing At Random - Rastgele):**
    - Eksiklik, veri setindeki diÄŸer gÃ¶zlemlenen deÄŸiÅŸkenlerle aÃ§Ä±klanabilir.
    - *Ã–rnek:* Erkeklerin depresyon anketini doldurma olasÄ±lÄ±ÄŸÄ±nÄ±n kadÄ±nlara gÃ¶re daha dÃ¼ÅŸÃ¼k olmasÄ±. Burada eksiklik "Cinsiyet" deÄŸiÅŸkeni ile iliÅŸkilidir.
    - *Ã‡Ã¶zÃ¼m:* DiÄŸer deÄŸiÅŸkenleri kullanarak tahminleme (Imputation) yapÄ±lmalÄ±dÄ±r.

3.  **MNAR (Missing Not At Random - Rastgele Olmayan):**
    - Eksiklik, eksik olan deÄŸerin kendisiyle iliÅŸkilidir.
    - *Ã–rnek:* Obezite anketinde, kilosu Ã§ok yÃ¼ksek olan kiÅŸilerin kilo bilgisini girmemesi.
    - *Analiz:* En zor durumdur. Doldurma yapmak sonucu bozabilir. Ã–zel modelleme gerekir.

#### Eksik Veri ile BaÅŸa Ã‡Ä±kma Stratejileri

**A. Silme (Deletion)**
- **Listwise (SatÄ±r Silme):** En az bir hÃ¼cresi eksik olan satÄ±rÄ± tamamen sil. Veri kaybÄ± az ise (%5 altÄ±) ve durum MCAR ise uygundur.
- **Pairwise:** Sadece analiz edilen iki deÄŸiÅŸken (korelasyon vb.) doluysa kullan, diÄŸerlerini yok say.
- **Dropping Features (SÃ¼tun Silme):** Bir sÃ¼tunun bÃ¼yÃ¼k Ã§oÄŸunluÄŸu (%60-70+) boÅŸsa o Ã¶zelliÄŸi analizden Ã§Ä±karmak.

**B. Doldurma (Imputation)**
- **Ä°statistiksel YÃ¶ntemler:** SayÄ±sal veriler iÃ§in Ortalama/Medyan, kategorik veriler iÃ§in Mod (en sÄ±k tekrar eden) atama. Basittir ancak verinin varyansÄ±nÄ± yapay olarak dÃ¼ÅŸÃ¼rÃ¼r.
- **Zaman Serisi YÃ¶ntemleri:** Bir Ã¶nceki deÄŸeri (Forward Fill) veya bir sonraki deÄŸeri (Backward Fill) kopyalama.
- **K-NN Imputation:** Eksik Ã¶rneÄŸe Ã¶znitelik uzayÄ±nda en benzeyen 'k' adet komÅŸuyu bulup onlarÄ±n ortalamasÄ±nÄ± alma.
- **Model TabanlÄ± (Regression/Iterative):** Eksik deÄŸiÅŸkeni "hedef deÄŸiÅŸken" (target) kabul edip diÄŸer deÄŸiÅŸkenlerle onu tahmin eden bir model kurma (MICE - Multivariate Imputation by Chained Equations).

### 3. GÃ¼rÃ¼ltÃ¼lÃ¼ Veri ve DÃ¼zeltme

**GÃ¼rÃ¼ltÃ¼**, Ã¶lÃ§Ã¼len deÄŸiÅŸkendeki rastgele hata veya varyanstÄ±r.

#### GÃ¼rÃ¼ltÃ¼ Azaltma (Smoothing) Teknikleri
1.  **Binning (Kutulama/Ã–bekleme):** SÄ±ralÄ± veri deÄŸerlerini "kutulara" bÃ¶lerek yerel yumuÅŸatma saÄŸlar.
    - *Equal-width:* DeÄŸer aralÄ±ÄŸÄ±nÄ± eÅŸit parÃ§alara bÃ¶lme (0-10, 10-20...).
    - *Equal-depth:* Her kutuda eÅŸit sayÄ±da veri olacak ÅŸekilde bÃ¶lme.
    - *Smoothing methods:* Kutudaki deÄŸerleri kutu ortalamasÄ± (mean) veya medyanÄ± ile deÄŸiÅŸtirme.
2.  **Regresyon:** Veriyi temsil eden en iyi doÄŸruyu/eÄŸriyi bularak, noktalarÄ± bu fonksiyona yaklaÅŸtÄ±rma.
3.  **AykÄ±rÄ± DeÄŸer Analizi (Clustering/IQR):** KÃ¼meleme algoritmalarÄ± ile gruplarÄ±n dÄ±ÅŸÄ±nda kalanlarÄ± tespit etme veya IQR (Interquartile Range) yÃ¶ntemi ile alt/Ã¼st sÄ±nÄ±rlarÄ± aÅŸanlarÄ± temizleme.

### 4. Veri DÃ¶nÃ¼ÅŸtÃ¼rme (Data Transformation)

Ham veriyi, madencilik algoritmalarÄ±nÄ±n daha verimli Ã§alÄ±ÅŸacaÄŸÄ± bir matematiksel uzaya taÅŸÄ±ma iÅŸlemidir.

#### 4.1. Ã–lÃ§eklendirme (Scaling) neden gereklidir?
Mesafe tabanlÄ± algoritmalar (KNN, K-Means, SVM) ve Gradient Descent kullanan yÃ¶ntemler (Sinir AÄŸlarÄ±, Lojistik Regresyon), deÄŸiÅŸkenlerin sayÄ±sal bÃ¼yÃ¼klÃ¼klerinden etkilenir. Ã–rneÄŸin, "YaÅŸ" (0-100) ve "MaaÅŸ" (0-50000) deÄŸiÅŸkenleri varsa, model "MaaÅŸ" deÄŸiÅŸkenindeki 1 birimlik deÄŸiÅŸimi Ã¶nemsiz, "YaÅŸ"takini Ã¶nemli gÃ¶rebilir veya tam tersi mesafe hesabÄ±nda MaaÅŸ domine edebilir.

**A. Min-Max Normalization:**
- Veriyi belirli bir aralÄ±ÄŸa (genellikle [0, 1]) lineer olarak sÄ±kÄ±ÅŸtÄ±rÄ±r.
- **FormÃ¼l:** $X_{yeni} = \frac{X - X_{min}}{X_{max} - X_{min}}$
- *KullanÄ±m:* Veri daÄŸÄ±lÄ±mÄ± hakkÄ±nda bilgi yoksa veya gÃ¶rÃ¼ntÃ¼ iÅŸleme gibi (piksel deÄŸerleri) sÄ±nÄ±rlÄ± aralÄ±klar iÃ§in. Outlierlara karÅŸÄ± Ã§ok hassastÄ±r.

**B. Z-Score Standardization:**
- Veriyi ortalamasÄ± 0, standart sapmasÄ± 1 olacak ÅŸekilde (Standart Normal DaÄŸÄ±lÄ±m) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.
- **FormÃ¼l:** $X_{yeni} = \frac{X - \mu}{\sigma}$
- *KullanÄ±m:* Veride aykÄ±rÄ± deÄŸerler varsa Min-Max'e gÃ¶re daha direnÃ§lidir. BirÃ§ok ML algoritmasÄ± iÃ§in varsayÄ±lan tercihtir.

#### 4.2. AyrÄ±klaÅŸtÄ±rma (Discretization)
SÃ¼rekli veriyi kategorik aralÄ±klara bÃ¶lme. (YaÅŸ -> Ã‡ocuk, GenÃ§, YaÅŸlÄ±).
- Karar aÄŸacÄ± gibi algoritmalarÄ±n performansÄ±nÄ± artÄ±rabilir ve gÃ¼rÃ¼ltÃ¼ etkisini azaltÄ±r.

### 5. Veri Entegrasyonu ve Ä°ndirgeme
- **Veri Entegrasyonu:** FarklÄ± veritabanlarÄ±ndan gelen verilerin birleÅŸtirilmesi.
  - *Schema Matching:* FarklÄ± isimlendirmeleri eÅŸleÅŸtirme (Cust_ID = Customer_Number).
  - *Redundancy:* Korelasyon analizi ile tekrar eden bilgilerin (Ã¶rn: DoÄŸum tarihi varken YaÅŸ bilgisinin de olmasÄ±) tespiti.
- **Veri Ä°ndirgeme:**
  - **Boyut Ä°ndirgeme (Dimensionality Reduction):** PCA (Principal Component Analysis) gibi yÃ¶ntemlerle verinin Ã¶zÃ¼nÃ¼ koruyarak Ã¶znitelik sayÄ±sÄ±nÄ± azaltma.
  - **Ã–znitelik SeÃ§imi (Feature Selection):** Modele en Ã§ok katkÄ± saÄŸlayan sÃ¼tunlarÄ± seÃ§me, diÄŸerlerini atma.

### 6. Veri Kodlama (Encoding)

Makine Ã¶ÄŸrenmesi modelleri matematiksel iÅŸlemler yapar, metin (string) veriyi iÅŸleyemez.

- **Label Encoding:** Kategorileri 0, 1, 2 gibi tamsayÄ±lara Ã§evirir.
  - *Risk:* Model, sayÄ±lar arasÄ±nda bÃ¼yÃ¼klÃ¼k iliÅŸkisi kurabilir (Elma=1, Armut=2 -> Armut > Elma?). Sadece Ordinal (sÄ±ralÄ±) verilerde (EÄŸitim Seviyesi vb.) kullanÄ±lmalÄ±dÄ±r.
- **One-Hot Encoding:** Her kategori iÃ§in yeni bir sÃ¼tun (0/1) oluÅŸturur.
  - *Risk:* Kategori sayÄ±sÄ± Ã§ok fazlaysa (Ã¶rn: 1000 farklÄ± mahalle) Ã§ok fazla sÃ¼tun oluÅŸur (Dummy Variable Trap ve Boyut Laneti).

## ğŸ’» Uygulama Ä°Ã§eriÄŸi

### Lab 1: Pandas ile Veri Temizleme
- CSV dosyasÄ± okuma
- Eksik deÄŸerleri tespit etme ve doldurma
- Duplicated deÄŸerleri bulma ve silme
- Veri tipleri dÃ¶nÃ¼ÅŸtÃ¼rme

### Lab 2: Veri DÃ¶nÃ¼ÅŸtÃ¼rme ve Normalizasyon
- Min-Max normalization
- Z-score standardization
- Log transformation
- One-hot encoding

## ğŸ“ Ã–devler

### Ã–dev 1: Veri Temizleme Projesi
Verilen kirli veri setini temizleyin ve rapor hazÄ±rlayÄ±n

### Ã–dev 2: Pandas AlÄ±ÅŸtÄ±rmalarÄ±
10 farklÄ± pandas operasyonu yapÄ±n

## ğŸ“– Okuma Listesi

### Zorunlu
- Han et al., BÃ¶lÃ¼m 3: Data Preprocessing
- Pandas DokÃ¼mantasyonu

### Ã–nerilen
- "Tidy Data" - Hadley Wickham
- "Missing Data Imputation" - Little & Rubin

## ğŸ”‘ Anahtar Kavramlar
- Missing values (MCAR, MAR, MNAR)
- Imputation techniques
- Normalization vs Standardization
- Outlier detection
- One-hot encoding
- Data quality dimensions

## ğŸ’¡ Pratik Ä°puÃ§larÄ±

1. **Her zaman veriyi inceleyin:**
   ```python
   df.info()
   df.describe()
   df.isnull().sum()
   ```

2. **Eksik veri oranÄ±nÄ± kontrol edin:**
   - %5'ten az: Silebilirsiniz
   - %5-20: Doldurma dÃ¼ÅŸÃ¼nÃ¼n
   - %20+: Dikkatli olun, Ã¶zniteliÄŸi kaldÄ±rabilirsiniz

3. **AykÄ±rÄ± deÄŸerleri gÃ¶rselleÅŸtirin:**
   - Boxplot kullanÄ±n
   - IQR yÃ¶ntemi uygulayÄ±n

4. **Normalizasyon seÃ§imi:**
   - Gaussian daÄŸÄ±lÄ±m: Standardization
   - Bounded deÄŸerler: Min-Max normalization
   - Tree-based modeller: Genelde normalizasyon gereksiz

## â“ SÄ±kÃ§a Sorulan Sorular

**S: Eksik deÄŸerleri silmeli mi doldurmalÄ± mÄ±yÄ±m?**
C: %5'ten az eksiklik varsa silebilirsiniz. Daha fazlaysa, verinin MCAR/MAR/MNAR olup olmadÄ±ÄŸÄ±na bakÄ±n ve uygun imputation yÃ¶ntemi seÃ§in.

**S: Normalizasyon zorunlu mu?**
C: Model tipine baÄŸlÄ±. KNN, SVM, Neural Networks iÃ§in Ã¶nemlidir. Karar aÄŸaÃ§larÄ± ve Random Forest iÃ§in gerekli deÄŸildir.

**S: One-hot encoding ne zaman kullanÄ±lÄ±r?**
C: Nominal (sÄ±rasÄ±z) kategorik deÄŸiÅŸkenler iÃ§in. Ordinal deÄŸiÅŸkenler iÃ§in label encoding tercih edilebilir.

## ğŸ“Š Ã–rnek Kod ParÃ§alarÄ±

```python
import pandas as pd
import numpy as np

# Veri okuma
df = pd.read_csv('data.csv')

# Eksik deÄŸer kontrolÃ¼
print(df.isnull().sum())

# Eksik deÄŸerleri doldurma
df['age'].fillna(df['age'].mean(), inplace=True)

# Normalizasyon
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
df[['age', 'salary']] = scaler.fit_transform(df[['age', 'salary']])

# One-hot encoding
df = pd.get_dummies(df, columns=['city'])
```

---

**Sonraki Hafta:** KeÅŸifsel Veri Analizi ve GÃ¶rselleÅŸtirme