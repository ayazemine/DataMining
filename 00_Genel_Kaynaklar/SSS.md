# Veri MadenciliÄŸi SÄ±kÃ§a Sorulan Sorular (SSS)

## ğŸ“š Genel Ders SorularÄ±

### Ders HakkÄ±nda

**S: Bu ders iÃ§in Ã¶n koÅŸul var mÄ±?**
C: Temel programlama bilgisi (Python tercih edilir) ve temel istatistik bilgisi yeterlidir. Ä°leri dÃ¼zey matematik gerekmez.

**S: Python mi R mÄ± Ã¶ÄŸrenmeliyim?**
C: Python Ã¶neririz. Daha genel amaÃ§lÄ±, endÃ¼stride yaygÄ±n kullanÄ±lÄ±r ve daha fazla kaynak bulunur.

**S: Dersi geÃ§mek iÃ§in minimum not nedir?**
C: 60/100 genel ortalama ile dersi geÃ§ebilirsiniz.

**S: DevamsÄ±zlÄ±k sÄ±nÄ±rÄ± nedir?**
C: %30 devamsÄ±zlÄ±k yapmÄ±ÅŸ Ã¶ÄŸrenciler sÄ±nava giremez (14 haftanÄ±n 4'Ã¼nden fazla).

### DeÄŸerlendirme

**S: Vize ve final sÄ±nav formatÄ± nasÄ±l?**
C: 
- Vize: Ã‡oktan seÃ§meli + aÃ§Ä±k uÃ§lu sorular (7. hafta)
- Final: KapsamlÄ± yazÄ±lÄ± sÄ±nav + proje sunumu (14. hafta)

**S: Ã–devler zorunlu mu?**
C: Evet, Ã¶devler toplam notun %20'sini oluÅŸturur ve teslim edilmesi zorunludur.

**S: Grup projesinde bireysel deÄŸerlendirme var mÄ±?**
C: Evet, grup notu + bireysel katkÄ± deÄŸerlendirmesi yapÄ±lÄ±r.

---

## ğŸ’» Teknik Sorular

### Kurulum ve Ortam

**S: Anaconda kurulumu zorunlu mu?**
C: HayÄ±r, ancak ÅŸiddetle tavsiye edilir. Alternatif olarak pip ile kÃ¼tÃ¼phaneler kurabilirsiniz.

**S: Jupyter Notebook Ã§alÄ±ÅŸmÄ±yor, ne yapmalÄ±yÄ±m?**
C:
```bash
# Terminalde ÅŸunlarÄ± deneyin:
jupyter notebook --generate-config
# TarayÄ±cÄ± ayarlarÄ±nÄ±zÄ± kontrol edin
# Anaconda Prompt'tan Ã§alÄ±ÅŸtÄ±rmayÄ± deneyin
```

**S: Mac/Linux kullanÄ±yorum, farklÄ±lÄ±k var mÄ±?**
C: HayÄ±r, Python platform baÄŸÄ±msÄ±zdÄ±r. BazÄ± komutlar terminal/command prompt'ta farklÄ± olabilir.

### Python ve KÃ¼tÃ¼phaneler

**S: Pandas ile NumPy arasÄ±ndaki fark nedir?**
C:
- **NumPy:** SayÄ±sal hesaplamalar, diziler (arrays)
- **Pandas:** Veri manipÃ¼lasyonu, DataFrame yapÄ±sÄ±, daha kullanÄ±cÄ± dostu

**S: Scikit-learn versiyonu Ã¶nemli mi?**
C: Evet, bazÄ± fonksiyonlar versiyonlar arasÄ± deÄŸiÅŸebilir. 1.0+ versiyonunu kullanmanÄ±zÄ± Ã¶neririz.

**S: GPU gerekli mi?**
C: HayÄ±r, derste iÅŸlenen konular iÃ§in CPU yeterlidir. Derin Ã¶ÄŸrenme iÃ§in GPU faydalÄ± olabilir.

---

## ğŸ“Š Veri MadenciliÄŸi KavramlarÄ±

### Genel Kavramlar

**S: Veri madenciliÄŸi ile makine Ã¶ÄŸrenmesi arasÄ±ndaki fark nedir?**
C:
- **Veri MadenciliÄŸi:** Daha geniÅŸ kavram, veri keÅŸfi, temizleme, gÃ¶rselleÅŸtirme, analiz
- **Makine Ã–ÄŸrenmesi:** Veri madenciliÄŸinin bir alt kÃ¼mesi, model oluÅŸturma ve tahmin

**S: Supervised vs Unsupervised learning farkÄ±?**
C:
- **Supervised:** Etiketli veri ile Ã¶ÄŸrenme (sÄ±nÄ±flandÄ±rma, regresyon)
- **Unsupervised:** Etiketsiz veri (kÃ¼meleme, boyut indirgeme)

**S: SÄ±nÄ±flandÄ±rma ile kÃ¼meleme arasÄ±ndaki fark?**
C:
- **SÄ±nÄ±flandÄ±rma:** Ã–nceden tanÄ±mlÄ± sÄ±nÄ±flara atama (supervised)
- **KÃ¼meleme:** Benzer verileri gruplama (unsupervised)

### Algoritmalar

**S: Hangi algoritmayÄ± ne zaman kullanmalÄ±yÄ±m?**
C:
- **Karar AÄŸaÃ§larÄ±:** Yorumlanabilirlik Ã¶nemli, kategorik + sayÄ±sal veri
- **k-NN:** Basit problemler, kÃ¼Ã§Ã¼k-orta veri setleri
- **SVM:** YÃ¼ksek boyutlu veri, ikili sÄ±nÄ±flandÄ±rma
- **Random Forest:** Genel amaÃ§lÄ±, robust
- **NaÃ¯ve Bayes:** Metin sÄ±nÄ±flandÄ±rma, hÄ±z Ã¶nemli

**S: En iyi algoritma hangisi?**
C: "No Free Lunch Theorem" - Her problem iÃ§in en iyi algoritma yoktur. Veri setinize gÃ¶re deneyerek bulmalÄ±sÄ±nÄ±z.

**S: Karar aÄŸacÄ± neden overfit oluyor?**
C: AÄŸaÃ§ Ã§ok derinleÅŸirse eÄŸitim verisini ezberler. Ã‡Ã¶zÃ¼m: max_depth, min_samples_split gibi parametrelerle sÄ±nÄ±rlayÄ±n veya pruning yapÄ±n.

### Veri Ã–n Ä°ÅŸleme

**S: Eksik deÄŸerleri silmeli mi doldurmalÄ± mÄ±yÄ±m?**
C:
- < %5 eksik: Silebilirsiniz
- %5-20: Doldurma dÃ¼ÅŸÃ¼nÃ¼n (ortalama, medyan, mod)
- > %20: Dikkatli olun, Ã¶zniteliÄŸi kaldÄ±rabilirsiniz

**S: Normalizasyon her zaman gerekli mi?**
C:
Gerekli:
- KNN, SVM, Neural Networks
- Gradient descent kullanan algoritmalar

Gereksiz:
- Karar aÄŸaÃ§larÄ±
- Random Forest
- Naive Bayes

**S: One-hot encoding ne zaman kullanÄ±lÄ±r?**
C: Nominal (sÄ±rasÄ±z) kategorik deÄŸiÅŸkenler iÃ§in. Ã–rnek: Renk (kÄ±rmÄ±zÄ±, mavi, yeÅŸil).
Ordinal (sÄ±ralÄ±) deÄŸiÅŸkenler iÃ§in label encoding yeterli. Ã–rnek: EÄŸitim (lise, lisans, yÃ¼ksek lisans).

### Model DeÄŸerlendirme

**S: Accuracy yeterli bir metrik mi?**
C: HayÄ±r, Ã¶zellikle dengesiz veri setlerinde yanÄ±ltÄ±cÄ± olabilir. Precision, Recall, F1-Score da bakÄ±n.

**S: Overfitting nasÄ±l tespit edilir?**
C:
- EÄŸitim skoru yÃ¼ksek, test skoru dÃ¼ÅŸÃ¼k
- Cross-validation skoru test skorundan Ã§ok farklÄ±
- Validation curve grafiÄŸinde bÃ¼yÃ¼k fark

**S: Train-test split oranÄ± ne olmalÄ±?**
C:
- Genel: 80-20 veya 70-30
- KÃ¼Ã§Ã¼k veri (<1000): 60-40 veya cross-validation
- BÃ¼yÃ¼k veri (>100K): 90-10 bile olabilir

**S: K-fold cross-validation'da K kaÃ§ olmalÄ±?**
C:
- Genelde K=5 veya K=10
- KÃ¼Ã§Ã¼k veri setlerinde K=n (Leave-One-Out)
- Hesaplama maliyeti yÃ¼ksekse K=3

---

## ğŸ”§ Pratik Problemler ve Ã‡Ã¶zÃ¼mler

### Hata MesajlarÄ±

**S: "ModuleNotFoundError: No module named 'sklearn'"**
C:
```bash
pip install scikit-learn
# veya
conda install scikit-learn
```

**S: "ValueError: could not convert string to float"**
C: Kategorik verileri encode etmelisiniz:
```python
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['column'] = le.fit_transform(df['column'])
```

**S: "MemoryError" hatasÄ± alÄ±yorum**
C:
- Veri setini parÃ§alara bÃ¶lÃ¼n
- Chunk processing kullanÄ±n
- Gereksiz sÃ¼tunlarÄ± silin
- Daha kÃ¼Ã§Ã¼k veri tipi kullanÄ±n (float32 yerine float16)

### Performans SorunlarÄ±

**S: Modelim Ã§ok yavaÅŸ Ã§alÄ±ÅŸÄ±yor**
C:
- Veri setini kÃ¼Ã§Ã¼ltÃ¼n (sampling)
- PCA ile boyut indirgeme yapÄ±n
- Daha basit algoritma deneyin
- Hiperparametre sayÄ±sÄ±nÄ± azaltÄ±n
- Paralel iÅŸleme kullanÄ±n (n_jobs=-1)

**S: Cross-validation Ã§ok uzun sÃ¼rÃ¼yor**
C:
- K deÄŸerini azaltÄ±n (10 yerine 5)
- Daha az parametre kombinasyonu deneyin
- RandomizedSearchCV kullanÄ±n (GridSearchCV yerine)

---

## ğŸ“– Ã–ÄŸrenme Stratejileri

**S: MatematiÄŸi anlamadan veri madenciliÄŸi Ã¶ÄŸrenebilir miyim?**
C: Evet, baÅŸlangÄ±Ã§ seviyesinde. Ancak ileri seviyede matematik bilgisi faydalÄ±dÄ±r. Ã–nce pratik yapÄ±n, sonra teoriye girin.

**S: En iyi Ã¶ÄŸrenme kaynaÄŸÄ± nedir?**
C:
1. Hands-on practice (en Ã¶nemli)
2. Kaggle competitions
3. Online kurslar (Coursera, edX)
4. Kitaplar (Python Machine Learning)
5. AraÅŸtÄ±rma makaleleri (ileri seviye)

**S: Kaggle'a nasÄ±l baÅŸlamalÄ±yÄ±m?**
C:
1. Titanic competition ile baÅŸlayÄ±n (baÅŸlangÄ±Ã§)
2. BaÅŸkalarÄ±n notebook'larÄ±nÄ± inceleyin
3. Kendi Ã§Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ geliÅŸtirin
4. TopluluÄŸa katÄ±lÄ±n, sorular sorun

**S: GÃ¼nde kaÃ§ saat Ã§alÄ±ÅŸmalÄ±yÄ±m?**
C:
- Minimum: 2 saat (ders + lab)
- Ã–nerilen: 3-4 saat
- Hafta sonu: Projelere odaklanÄ±n

---

## ğŸ“ Kariyer ve Gelecek

**S: Veri bilimci olmak iÃ§in baÅŸka ne Ã¶ÄŸrenmeliyim?**
C:
- SQL ve veritabanlarÄ±
- Ä°leri Python (OOP, decorators)
- Git/GitHub
- Derin Ã¶ÄŸrenme (TensorFlow/PyTorch)
- Cloud platformlarÄ± (AWS, Azure, GCP)
- Ä°ÅŸ bilgisi (domain knowledge)

**S: Hangi sektÃ¶rlerde iÅŸ imkanÄ± var?**
C:
- Fintech ve bankacÄ±lÄ±k
- E-ticaret
- SaÄŸlÄ±k
- TelekomÃ¼nikasyon
- Otomotiv
- Perakende
- Sosyal medya ve reklam

**S: Staj nasÄ±l bulabilirim?**
C:
- Kaggle profili oluÅŸturun
- GitHub'da projelerinizi paylaÅŸÄ±n
- LinkedIn'de aktif olun
- Åirketlere direkt baÅŸvurun
- Ãœniversite kariyer fuarlarÄ±na katÄ±lÄ±n

---

## ğŸ†˜ YardÄ±m ve Destek

**S: TakÄ±ldÄ±ÄŸÄ±m bir konu olursa nereye sorabilirim?**
C:
1. Ders forumu/LMS
2. Ofis saatleri (Pazartesi-Ã‡arÅŸamba 14:00-16:00)
3. E-posta: [ders_hocasi@uni.edu.tr]
4. Stack Overflow (genel Python sorularÄ±)
5. Kaggle forums

**S: Proje iÃ§in grup bulamÄ±yorum**
C: Ders forumunda "Grup arÄ±yorum" baÅŸlÄ±ÄŸÄ± aÃ§Ä±n veya ofis saatlerinde bildirin, yardÄ±mcÄ± oluruz.

**S: SÄ±nav sorularÄ± nereden Ã§Ä±kÄ±yor?**
C:
- Ders notlarÄ± (%50)
- Lab uygulamalarÄ± (%30)
- Ã–devler (%20)

---

## ğŸ’¡ Ä°puÃ§larÄ± ve PÃ¼f Noktalar

**S: HÄ±zlÄ± Ã¶ÄŸrenmenin sÄ±rrÄ± nedir?**
C:
1. Her gÃ¼n kod yazÄ±n (consistency)
2. Hatalardan Ã¶ÄŸrenin (debug etmeyi Ã¶ÄŸrenin)
3. BaÅŸkalarÄ±nÄ±n kodunu okuyun
4. Projeler yapÄ±n (teori deÄŸil pratik)
5. Toplulukta aktif olun

**S: En Ã§ok yapÄ±lan hatalar nelerdir?**
C:
1. Data leakage (test verisini eÄŸitimde kullanma)
2. Overfit etmeyi fark etmeme
3. Cross-validation yapmama
4. Ã–lÃ§eklendirmeyi unutma
5. Baseline model yapmama
6. SonuÃ§larÄ± yorumlamama

**S: Kod yazarken nelere dikkat etmeliyim?**
C:
- AnlamlÄ± deÄŸiÅŸken isimleri
- Yorumlar ekleyin
- Fonksiyonlara bÃ¶len (modÃ¼ler kod)
- Version control kullanÄ±n (Git)
- Notebook'larÄ± dÃ¼zenli tutun

---

## ğŸ“§ Ä°letiÅŸim

BaÅŸka sorularÄ±nÄ±z iÃ§in:
- **E-posta:** [ders_hocasi@universite.edu.tr]
- **Forum:** [LMS linki]
- **Ofis Saatleri:** Pazartesi ve Ã‡arÅŸamba, 14:00-16:00

**Son GÃ¼ncelleme:** Åubat 2026
