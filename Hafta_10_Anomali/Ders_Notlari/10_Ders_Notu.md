# Hafta 10: AykÄ±rÄ± DeÄŸer Tespiti (Anomaly Detection)

## ğŸ“‹ Anomali Nedir?

**Anomali (Outlier):** Normal davranÄ±ÅŸtan belirgin ÅŸekilde farklÄ± olan gÃ¶zlem.

### Anomali Tipleri

**1. Point Anomaly (Nokta Anomalisi)**
```
Tek bir veri noktasÄ± anormal
Ã–rn: 1000 TL yerine 1,000,000 TL iÅŸlem
```

**2. Contextual Anomaly (BaÄŸlamsal Anomali)**
```
Belirli bir baÄŸlamda anormal
Ã–rn: KÄ±ÅŸÄ±n 35Â°C sÄ±caklÄ±k
```

**3. Collective Anomaly (Toplu Anomali)**
```
Tek baÅŸÄ±na normal, birlikte anormal
Ã–rn: AynÄ± IP'den 1000 login denemesi
```

## ğŸ¯ KullanÄ±m AlanlarÄ±

- **Fraud Detection:** Kredi kartÄ± dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ±
- **Network Security:** Siber saldÄ±rÄ± tespiti
- **Healthcare:** HastalÄ±k teÅŸhisi
- **Manufacturing:** ArÄ±za tespiti
- **Finance:** Piyasa manipÃ¼lasyonu

## ğŸ“Š Ä°statistiksel YÃ¶ntemler

### 1. Z-Score (Standard Score)

```
Z = (x - Î¼) / Ïƒ

|Z| > 3 â†’ Anomali
```

**Python:**
```python
from scipy import stats
import numpy as np

data = np.array([10, 12, 12, 13, 12, 11, 14, 100])
z_scores = np.abs(stats.zscore(data))
anomalies = np.where(z_scores > 3)

print("Anomali indexler:", anomalies)
```

**Avantajlar:** âœ… Basit, hÄ±zlÄ±
**Dezavantajlar:** âŒ Gaussian varsayÄ±mÄ±, tek boyut

### 2. IQR (Interquartile Range)

```
Q1 = 25. percentile
Q3 = 75. percentile
IQR = Q3 - Q1

Anomali: x < Q1 - 1.5Ã—IQR veya x > Q3 + 1.5Ã—IQR
```

**Python:**
```python
Q1 = np.percentile(data, 25)
Q3 = np.percentile(data, 75)
IQR = Q3 - Q1

lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

anomalies = (data < lower_bound) | (data > upper_bound)
```

**Avantajlar:** âœ… Outlier'a dayanÄ±klÄ±, non-parametric
**Dezavantajlar:** âŒ Tek boyut

## ğŸ¤– Makine Ã–ÄŸrenmesi YÃ¶ntemleri

### 1. Isolation Forest

**Ä°lke:** Anomaliler izole edilmesi daha kolay.

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
1. Rastgele Ã¶znitelik seÃ§
2. Rastgele split deÄŸeri seÃ§
3. Veriyi bÃ¶l
4. Tekrarla
5. Anomaliler daha az split'le izole edilir

```python
from sklearn.ensemble import IsolationForest

iso_forest = IsolationForest(contamination=0.1, random_state=42)
predictions = iso_forest.fit_predict(X)
# -1: anomaly, 1: normal

anomaly_scores = iso_forest.score_samples(X)  # Anomaly score
```

**Parametreler:**
- `contamination`: Anomali oranÄ± (0.1 = %10)
- `n_estimators`: AÄŸaÃ§ sayÄ±sÄ± (default: 100)
- `max_samples`: Her aÄŸaÃ§ iÃ§in sample sayÄ±sÄ±

**Avantajlar:**
âœ… HÄ±zlÄ±
âœ… Ã‡ok boyutlu veri
âœ… Unsupervised
âœ… Outlier'a dayanÄ±klÄ±

### 2. Local Outlier Factor (LOF)

**Ä°lke:** Bir noktanÄ±n komÅŸularÄ±na gÃ¶re yoÄŸunluk anomalisini Ã¶lÃ§.

**LOF Skoru:**
```
LOF > 1: Anomali (dÃ¼ÅŸÃ¼k yoÄŸunluk)
LOF â‰ˆ 1: Normal
LOF < 1: Ä°Ã§ nokta (yÃ¼ksek yoÄŸunluk)
```

```python
from sklearn.neighbors import LocalOutlierFactor

lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
predictions = lof.fit_predict(X)
# -1: anomaly, 1: normal

lof_scores = lof.negative_outlier_factor_  # LOF skorlarÄ± (negatif)
```

**Parametreler:**
- `n_neighbors`: KomÅŸu sayÄ±sÄ± (10-50 arasÄ±)
- `contamination`: Anomali oranÄ±

**Avantajlar:**
âœ… Yerel yoÄŸunluÄŸa duyarlÄ±
âœ… FarklÄ± yoÄŸunluktaki kÃ¼melerde etkili

**Dezavantajlar:**
âŒ YavaÅŸ (her nokta iÃ§in mesafe hesaplar)
âŒ YÃ¼ksek boyutta zayÄ±f

### 3. One-Class SVM

**Ä°lke:** Normal verileri Ã§evreleyen bir sÄ±nÄ±r bul.

```python
from sklearn.svm import OneClassSVM

ocsvm = OneClassSVM(kernel='rbf', gamma=0.001, nu=0.1)
predictions = ocsvm.fit_predict(X)
# -1: anomaly, 1: normal
```

**Parametreler:**
- `nu`: Anomali oranÄ± Ã¼st sÄ±nÄ±rÄ±
- `kernel`: 'rbf', 'linear', 'poly'
- `gamma`: RBF kernel parametresi

### 4. Autoencoder (Derin Ã–ÄŸrenme)

**Ä°lke:** Normal veriyi Ã¶ÄŸren, reconstruct et. YÃ¼ksek reconstruction error â†’ anomali.

```python
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

# Autoencoder
input_dim = X.shape[1]
encoding_dim = 8

input_layer = Input(shape=(input_dim,))
encoded = Dense(encoding_dim, activation='relu')(input_layer)
decoded = Dense(input_dim, activation='sigmoid')(encoded)

autoencoder = Model(input_layer, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# EÄŸitim
autoencoder.fit(X_train, X_train, epochs=50, batch_size=32, validation_split=0.1)

# Tahmin
reconstructions = autoencoder.predict(X_test)
mse = np.mean(np.power(X_test - reconstructions, 2), axis=1)
threshold = np.percentile(mse, 95)
anomalies = mse > threshold
```

## ğŸ” Zaman Serisi Anomali Tespiti

### 1. Moving Average

```python
window_size = 5
rolling_mean = data.rolling(window=window_size).mean()
rolling_std = data.rolling(window=window_size).std()

upper_bound = rolling_mean + 3 * rolling_std
lower_bound = rolling_mean - 3 * rolling_std

anomalies = (data > upper_bound) | (data < lower_bound)
```

### 2. ARIMA Residuals

```python
from statsmodels.tsa.arima.model import ARIMA

model = ARIMA(data, order=(1, 1, 1))
fitted = model.fit()
residuals = fitted.resid

threshold = 3 * np.std(residuals)
anomalies = np.abs(residuals) > threshold
```

### 3. Prophet (Facebook)

```python
from prophet import Prophet

df = pd.DataFrame({'ds': dates, 'y': values})
model = Prophet(interval_width=0.99)
model.fit(df)

forecast = model.predict(df)

# Anomali: gerÃ§ek deÄŸer prediction interval dÄ±ÅŸÄ±nda
anomalies = (df['y'] < forecast['yhat_lower']) | (df['y'] > forecast['yhat_upper'])
```

## ğŸ“ˆ DeÄŸerlendirme Metrikleri

### Etiketli Veri Varsa

```python
from sklearn.metrics import classification_report, confusion_matrix, f1_score

# y_true: 0=normal, 1=anomaly
print(classification_report(y_true, y_pred))

tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
print(f"True Negatives: {tn}")
print(f"False Positives: {fp}")
print(f"False Negatives: {fn}")
print(f"True Positives: {tp}")
```

### Etiketsiz Veri

- **Silhouette Score**
- **DBSCAN ile karÅŸÄ±laÅŸtÄ±rma**
- **Manuel inceleme**

## ğŸ’» Pratik Ã–rnek: Kredi KartÄ± Fraud Detection

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report

# Veri yÃ¼kleme
df = pd.read_csv('creditcard.csv')

# Ã–lÃ§eklendirme
scaler = StandardScaler()
df['Amount_scaled'] = scaler.fit_transform(df[['Amount']])

# Ã–znitelikler
features = df.drop(['Time', 'Class'], axis=1)
X = features.values
y = df['Class'].values  # 0: normal, 1: fraud

# Model
iso_forest = IsolationForest(contamination=0.001, random_state=42)
y_pred = iso_forest.fit_predict(X)

# -1 â†’ 1 (anomaly), 1 â†’ 0 (normal)
y_pred = np.where(y_pred == -1, 1, 0)

# DeÄŸerlendirme
print(classification_report(y, y_pred, target_names=['Normal', 'Fraud']))
```

## ğŸ¯ Hangi YÃ¶ntemi SeÃ§meli?

| Durum | Ã–nerilen YÃ¶ntem |
|-------|----------------|
| Tek boyutlu veri | Z-Score, IQR |
| Ã‡ok boyutlu, hÄ±zlÄ± | Isolation Forest |
| Yerel yoÄŸunluk Ã¶nemli | LOF |
| YÃ¼ksek boyutlu, karmaÅŸÄ±k | Autoencoder |
| Zaman serisi | Moving Average, Prophet |
| Etiketli veri var | Supervised learning (Random Forest, XGBoost) |

## ğŸ’¡ Ä°puÃ§larÄ±

1. **Contamination parametresi:** Domain knowledge ile belirle
2. **Preprocessing:** Scaling/normalization Ã¶nemli
3. **Multiple methods:** Birden fazla yÃ¶ntem dene, karÅŸÄ±laÅŸtÄ±r
4. **Threshold tuning:** Business requirements'a gÃ¶re ayarla
5. **False positives:** Ã‡ok anomali bulma, gerÃ§ek anormalileri kaÃ§Ä±rabilir
6. **Visualization:** Anomalileri gÃ¶rselleÅŸtir, manuel kontrol et
7. **Feature engineering:** Ä°yi Ã¶znitelikler anomali tespitini iyileÅŸtirir

## ğŸ“š KÃ¼tÃ¼phaneler

- **PyOD:** Python Outlier Detection (20+ algoritma)
- **scikit-learn:** IsolationForest, LOF, OneClassSVM
- **TensorFlow/Keras:** Autoencoder
- **Prophet:** Zaman serisi anomali
